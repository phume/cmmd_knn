\documentclass[conference]{IEEEtran}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}

\begin{document}

\title{When Does Context Help? An Empirical Study of Contextual Anomaly Detection for Transaction Monitoring}

\author{
\IEEEauthorblockN{Anonymous Author(s)}
\IEEEauthorblockA{Anonymous Institution}
}

\maketitle

\begin{abstract}
Contextual anomaly detection identifies data points that are normal globally but unusual within their specific context. While peer group analysis has long been used in anti-money laundering (AML) systems, the question of \emph{when} contextual methods provide value over global approaches remains understudied. We present an empirical comparison of Isolation Forest (IF), a global anomaly detector, against peer-normalized variants (PNKIF, PNKDIF) on three financial datasets. Our experiments with domain-grounded injection strategies reveal a clear pattern: IF excels at detecting globally unusual behavior, while peer-normalized methods excel at detecting behavior that is normal globally but unusual for a specific context (e.g., geographic arbitrage). We also find that the deep variant (PNKDIF) outperforms PNKIF at higher contamination rates. We propose using multiple methods as a diagnostic: disagreement between IF and contextual methods signals the presence of contextual anomalies. This provides practitioners with actionable guidance on method selection for transaction monitoring systems.
\end{abstract}

\begin{IEEEkeywords}
anomaly detection, contextual anomaly, anti-money laundering, isolation forest, peer group analysis
\end{IEEEkeywords}

\section{Introduction}

Anti-money laundering (AML) systems must detect suspicious transaction patterns across diverse customer populations. A key challenge is that ``normal'' behavior varies by context: a high-value international transfer may be routine for a multinational corporation but highly unusual for a domestic retail account. This observation motivates \emph{contextual anomaly detection}, where anomalies are defined relative to similar entities rather than the global population.

Peer group analysis has been used in financial crime detection since Bolton and Hand's seminal work~\cite{bolton2001peer}. The core idea is simple: compare each entity to its ``peers'' (similar entities based on context features) rather than to the entire population. Despite widespread industry adoption, there is limited empirical guidance on \emph{when} contextual methods provide value over simpler global approaches.

In this paper, we address the question: \textbf{When does context help in anomaly detection for transaction monitoring?}

Our contributions are:
\begin{enumerate}
    \item An empirical comparison of global (IF) vs. contextual (PNKIF, PNKDIF) anomaly detection on three financial datasets
    \item Domain-grounded injection strategies that simulate realistic AML typologies (geographic arbitrage, account misuse)
    \item Evidence that method effectiveness depends on anomaly type: IF for global anomalies, contextual methods for contextual anomalies
    \item Analysis of when deep projections (PNKDIF) outperform simple peer normalization (PNKIF)
    \item A practical diagnostic: run both methods; disagreement signals contextual anomalies
\end{enumerate}

\section{Related Work}

\subsection{Anomaly Detection in AML}

Machine learning for AML has been extensively surveyed~\cite{chen2018ml}. Common approaches include rule-based systems, supervised classification, and unsupervised anomaly detection. Isolation Forest~\cite{liu2008isolation} is widely used due to its efficiency and effectiveness on high-dimensional data.

\subsection{Contextual Anomaly Detection}

Contextual anomalies are data points that are unusual only within a specific context~\cite{song2007conditional}. Methods include:
\begin{itemize}
    \item \textbf{ROCOD}~\cite{liang2022robust}: K-NN based peer normalization with robust statistics
    \item \textbf{QCAD}~\cite{zhong2023qcad}: Quantile regression for conditional distributions
    \item \textbf{ConQuest}~\cite{calikus2024conquest}: Context discovery for anomaly detection
\end{itemize}

\subsection{Peer Group Analysis}

Bolton and Hand~\cite{bolton2001peer} introduced peer group analysis for fraud detection. The approach groups entities by context features and flags deviations from peer behavior. Our methods formalize this with kernel-weighted peer normalization.

\section{Methods}

\subsection{Problem Setting}

Given dataset $\{(\mathbf{c}_i, \mathbf{x}_i)\}_{i=1}^{N}$ where $\mathbf{c}_i \in \mathbb{R}^{d_c}$ is the context vector and $\mathbf{x}_i \in \mathbb{R}^{d_x}$ is the behavioral vector, we aim to detect anomalies that are unusual \emph{given their context}.

\subsection{Isolation Forest (IF)}

Isolation Forest~\cite{liu2008isolation} detects anomalies by measuring how easily a point can be isolated via random recursive partitioning. It operates on the concatenated features $[\mathbf{c}; \mathbf{x}]$ or behavior only $\mathbf{x}$, without explicitly modeling context-behavior relationships.

\subsection{Peer-Normalized Kernel Isolation Forest (PNKIF)}

PNKIF applies peer normalization before Isolation Forest:

\begin{enumerate}
    \item \textbf{Compute peer weights:} For each point $i$, compute RBF kernel weights to all other points based on context similarity:
    \[
    w_{ij} = \exp\left(-\frac{\|\mathbf{c}_i - \mathbf{c}_j\|^2}{2\gamma^2}\right)
    \]

    \item \textbf{Compute peer statistics:} Weighted mean and standard deviation of behavior:
    \[
    \boldsymbol{\mu}_i = \frac{\sum_j w_{ij} \mathbf{x}_j}{\sum_j w_{ij}}, \quad
    \boldsymbol{\sigma}_i = \sqrt{\frac{\sum_j w_{ij} (\mathbf{x}_j - \boldsymbol{\mu}_i)^2}{\sum_j w_{ij}}}
    \]

    \item \textbf{Normalize:} $\tilde{\mathbf{x}}_i = (\mathbf{x}_i - \boldsymbol{\mu}_i) / \boldsymbol{\sigma}_i$

    \item \textbf{Score:} Apply Isolation Forest to normalized behaviors $\{\tilde{\mathbf{x}}_i\}$
\end{enumerate}

\subsection{Deep Peer-Normalized Isolation Forest (PNKDIF)}

PNKDIF extends PNKIF by applying random MLP projections before Isolation Forest, inspired by Deep Isolation Forest~\cite{xu2023deep}:

\begin{enumerate}
    \item Apply peer normalization as in PNKIF to obtain $\tilde{\mathbf{x}}_i$
    \item Project through $M$ frozen random MLPs: $\mathbf{z}_i^{(m)} = \text{MLP}_m(\tilde{\mathbf{x}}_i)$
    \item Build separate Isolation Forest on each projection
    \item Average anomaly scores across projections
\end{enumerate}

The random projections create non-linear decision boundaries, potentially improving detection of complex anomaly patterns.

\section{Experimental Setup}

\subsection{Datasets}

We use three public financial datasets:

\begin{itemize}
    \item \textbf{SAML-D}~\cite{oztas2023saml}: Synthetic AML dataset with 30K accounts. Context: geography, payment type, currency (38 features after one-hot encoding). Behavior: transaction statistics (6 features).

    \item \textbf{PaySim}~\cite{lopez2016paysim}: Mobile money simulation with 30K transactions. Context: transaction type (5 features). Behavior: amounts and balances (5 features).

    \item \textbf{Credit Card}~\cite{dal2015calibrating}: Anonymized transactions with 30K samples. Context: time and amount (2 features). Behavior: PCA components V1-V28 (28 features).
\end{itemize}

\subsection{Injection Strategies}

Since original labels in these datasets correspond to globally unusual behavior, we inject contextual anomalies using domain-grounded strategies:

\begin{enumerate}
    \item \textbf{Geographic Swap (Contextual):} Simulate geographic arbitrage---a known FATF money laundering typology---by assigning behavior from one geographic region to accounts in another region.

    \item \textbf{Context Mismatch (Contextual):} Simulate account misuse by assigning behavior from a randomly different context group.

    \item \textbf{Velocity Anomaly (Global):} Scale transaction amounts by 2-5x, simulating structuring behavior.

    \item \textbf{Temporal Shift (Global):} Add systematic shifts (2-3 standard deviations) to behavior features.
\end{enumerate}

Injection rates: 1\%, 3\%, 5\%, 10\%.

\subsection{Evaluation}

We report AUROC across 10 random seeds for robustness. Methods compared:
\begin{itemize}
    \item \textbf{IF}: Isolation Forest on behavior only
    \item \textbf{IF\_concat}: Isolation Forest on concatenated context + behavior
    \item \textbf{ROCOD}: K-NN peer normalization with robust statistics~\cite{liang2022robust}
    \item \textbf{PNKIF}: Kernel-weighted peer normalization + IF
    \item \textbf{PNKDIF}: PNKIF + random MLP projections (deep variant)
\end{itemize}

\section{Results}

\subsection{Original Labels: Global Anomalies}

On original dataset labels, IF and IF\_concat consistently outperform contextual methods (Table~\ref{tab:original}).

\begin{table}[htbp]
\centering
\caption{AUROC on Original Labels (10 seeds)}
\label{tab:original}
\begin{tabular}{lccccc}
\toprule
Dataset & IF & IF\_concat & ROCOD & PNKIF & PNKDIF \\
\midrule
SAML-D & \textbf{0.937} & 0.896 & 0.419 & 0.869 & 0.842 \\
PaySim & 0.691 & \textbf{0.776} & 0.375 & 0.455 & 0.353 \\
CreditCard & \textbf{0.947} & 0.946 & 0.912 & 0.926 & 0.918 \\
\bottomrule
\end{tabular}
\end{table}

This is expected: original labels correspond to globally unusual behavior that IF detects effectively. Contextual methods add overhead without benefit when anomalies are globally detectable.

\subsection{Contextual Injection: Peer Methods Win}

On contextual anomalies (context mismatch), peer-normalized methods consistently outperform IF (Table~\ref{tab:contextual}).

\begin{table}[htbp]
\centering
\caption{AUROC on Context Mismatch Injection (PaySim, 10 seeds)}
\label{tab:contextual}
\begin{tabular}{lcccc}
\toprule
Rate & IF & PNKIF & PNKDIF & Winner \\
\midrule
1\% & \textbf{0.650} & 0.536 & 0.469 & IF \\
3\% & 0.615 & \textbf{0.633} & 0.586 & PNKIF \\
5\% & 0.591 & \textbf{0.663} & 0.616 & PNKIF \\
10\% & 0.563 & \textbf{0.690} & 0.677 & PNKIF \\
\bottomrule
\end{tabular}
\end{table}

At low injection rates (1\%), IF still wins because the contextual signal is weak. At higher rates (3-10\%), PNKIF consistently outperforms IF, with the gap widening as injection rate increases.

\textbf{Observation:} PNKIF performance \emph{increases} from 5\% to 10\% (0.663 $\rightarrow$ 0.690). This counterintuitive result occurs because more contextual anomalies create a stronger deviation signal from peer norms, making them easier to detect.

\subsection{Geographic Swap: PNKDIF Wins at High Rates}

On geographic swap injection, PNKDIF outperforms PNKIF at higher contamination rates (Table~\ref{tab:geoswap}).

\begin{table}[htbp]
\centering
\caption{AUROC on Geographic Swap Injection (PaySim, 10 seeds)}
\label{tab:geoswap}
\begin{tabular}{lcccc}
\toprule
Rate & IF & PNKIF & PNKDIF & Winner \\
\midrule
1\% & \textbf{0.610} & 0.549 & 0.500 & IF \\
3\% & 0.528 & \textbf{0.589} & 0.583 & PNKIF \\
5\% & 0.479 & 0.598 & \textbf{0.617} & PNKDIF \\
10\% & 0.422 & 0.599 & \textbf{0.628} & PNKDIF \\
\bottomrule
\end{tabular}
\end{table}

The deep projections in PNKDIF provide additional benefit when contamination is high, possibly by creating non-linear decision boundaries that better separate complex anomaly patterns.

\subsection{Global Injection: IF Wins}

On global-style anomalies (velocity, temporal shift), IF wins 100\% of scenarios. These anomalies stand out globally, so peer normalization provides no benefit.

\subsection{Summary Across All Experiments}

\begin{table}[htbp]
\centering
\caption{Win Rate by Injection Type (All Datasets)}
\label{tab:summary}
\begin{tabular}{lccc}
\toprule
Injection Type & IF & PNKIF & PNKDIF \\
\midrule
Context Mismatch & 4/12 & \textbf{8/12} & 0/12 \\
Geographic Swap & 4/12 & 4/12 & \textbf{4/12} \\
Velocity Anomaly & \textbf{12/12} & 0/12 & 0/12 \\
Temporal Shift & \textbf{12/12} & 0/12 & 0/12 \\
\bottomrule
\end{tabular}
\end{table}

\section{Discussion}

\subsection{When Does Context Help?}

Our results provide clear guidance:
\begin{itemize}
    \item \textbf{Use IF} when anomalies are globally unusual (unusual amounts, frequencies, or feature values) or when contamination is very low ($<$1\%)
    \item \textbf{Use PNKIF} when anomalies are contextually unusual and you need interpretability (peer comparison is explainable)
    \item \textbf{Use PNKDIF} when contamination is high ($>$5\%) and complex patterns are expected
\end{itemize}

\subsection{Effect of Injection Rate}

We observe that contextual method performance can \emph{improve} with higher injection rates. This occurs because:
\begin{itemize}
    \item More anomalies create stronger deviation from peer norms
    \item The ``mismatch'' signal becomes more pronounced
    \item AUROC benefits from having more positive samples to rank
\end{itemize}

Conversely, IF performance degrades at higher rates because global statistics become contaminated.

\subsection{Diagnostic Framework}

We propose running both IF and PNKIF on the same data:
\begin{itemize}
    \item If both agree: high confidence in the detection
    \item If IF flags but PNKIF doesn't: likely a global anomaly
    \item If PNKIF flags but IF doesn't: likely a contextual anomaly
    \item Large overall disagreement: dataset contains contextual anomalies
\end{itemize}

\subsection{Practical Implications for AML}

Contextual anomalies correspond to known money laundering typologies:
\begin{itemize}
    \item \textbf{Geographic arbitrage}: Domestic accounts with international transaction patterns
    \item \textbf{Account takeover}: Behavior inconsistent with account profile
    \item \textbf{Peer group deviation}: Activity unusual for customer segment
\end{itemize}

Standard IF may miss these if the behavior is common globally. Peer-normalized methods provide complementary detection.

\subsection{Limitations}

\begin{itemize}
    \item Injection-based evaluation: real contextual labels are rare in public datasets
    \item Context feature selection: performance depends on choosing appropriate context features
    \item Computational cost: PNKIF/PNKDIF require K-NN computation, adding overhead
    \item PNKDIF variance: deep projections introduce randomness, requiring multiple seeds
\end{itemize}

\section{Conclusion}

We presented an empirical study of contextual vs. global anomaly detection for transaction monitoring. Our experiments demonstrate that method effectiveness depends on anomaly type: IF for global anomalies, PNKIF for contextual anomalies at moderate contamination, and PNKDIF for high-contamination scenarios. We propose using multiple methods as a diagnostic tool. Future work includes validation on proprietary AML data with natural contextual labels and investigation of adaptive method selection.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
