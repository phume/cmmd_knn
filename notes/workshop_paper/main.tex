\documentclass[journal]{IEEEtran}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{tcolorbox}

\begin{document}

\title{When Does Context Help? An Empirical Study of Contextual Anomaly Detection for Transaction Monitoring}

\author{
\IEEEauthorblockN{Anonymous Author(s)}
\IEEEauthorblockA{Anonymous Institution}
}

\maketitle

\begin{abstract}
Contextual anomaly detection identifies data points that are normal globally but unusual within their specific context. While peer group analysis has long been used in anti-money laundering (AML) systems, the question of \emph{when} contextual methods provide value over global approaches remains understudied. This paper presents an empirical study---not a new detection algorithm---comparing Isolation Forest (IF) against peer-normalized variants on three financial datasets. Using controlled injection strategies grounded in AML typologies, we demonstrate a clear pattern: IF excels at detecting globally unusual behavior, while peer-normalized methods excel at detecting behavior that is normal globally but unusual for a specific context. At 10\% contextual contamination, PNKIF achieves 84\% higher precision at top-5\% than IF (38.8\% vs 21.1\%). Our key contribution is reframing contextual detection as a \emph{diagnostic tool}: we formalize a statistical test where low agreement between IF and PNKIF signals the presence of contextual structure. We provide open-source implementations and practical deployment guidance aligned with regulatory requirements. This provides practitioners with actionable guidance on method selection for transaction monitoring systems.
\end{abstract}

\begin{IEEEkeywords}
anomaly detection, contextual anomaly, anti-money laundering, isolation forest, peer group analysis
\end{IEEEkeywords}

% Practitioner Summary Box
\begin{tcolorbox}[colback=gray!10, colframe=gray!50, title=Practitioner Summary]
\textbf{Key Takeaways:}
\begin{itemize}
    \item Run both IF and PNKIF on your data; disagreement signals contextual anomalies
    \item If Agreement@5\% $<$ 25\%, your data likely contains contextual structure
    \item PNKIF improves precision by up to 84\% when contextual anomalies are present
    \item Use IF for globally unusual behavior; use PNKIF for peer-relative deviations
    \item Open-source implementation available: no GPU required, 8K+ transactions/second
\end{itemize}
\end{tcolorbox}

\section{Introduction}

Anti-money laundering (AML) systems must detect suspicious transaction patterns across diverse customer populations. A key challenge is that ``normal'' behavior varies by context: a high-value international transfer may be routine for a multinational corporation but highly unusual for a domestic retail account. This observation motivates \emph{contextual anomaly detection}, where anomalies are defined relative to similar entities rather than the global population.

Peer group analysis has been used in financial crime detection since Bolton and Hand's seminal work~\cite{bolton2001peer}. The core idea is simple: compare each entity to its ``peers'' (similar entities based on context features) rather than to the entire population. Despite widespread industry adoption, there is limited empirical guidance on \emph{when} contextual methods provide value over simpler global approaches.

In this paper, we address the question: \textbf{When does context help in anomaly detection for transaction monitoring?}

\subsection{Contributions}

This paper makes \emph{methodological and empirical} contributions, rather than proposing a universally superior anomaly detection model.

\begin{enumerate}
    \item \textbf{Empirical clarification of when context helps.} We provide a systematic empirical study showing that the effectiveness of contextual anomaly detection depends on the \emph{type} of anomaly present. Global anomaly detectors such as Isolation Forest excel when anomalies are globally unusual, while contextual methods are effective only when anomalies are normal globally but deviate relative to peer groups.

    \item \textbf{Formalized diagnostic test.} We propose a statistical test for contextual structure: if Agreement@5\% between IF and PNKIF falls below a threshold (25\%), reject the null hypothesis that context is uninformative. This provides practitioners with a decision rule.

    \item \textbf{Precision@K analysis.} Beyond AUROC, we show that PNKIF achieves 84\% higher precision at top-5\% compared to IF when contextual anomalies are present (38.8\% vs 21.1\%), directly translating to investigator efficiency gains.

    \item \textbf{Regulatory alignment.} We demonstrate how peer-normalized methods align with FATF risk-based monitoring requirements and provide explainable justifications suitable for SAR narratives.

    \item \textbf{Open-source implementation.} We provide a production-ready implementation requiring no GPU, processing 8,000+ transactions per second on standard hardware.
\end{enumerate}

\subsection{Scope and Non-Claims}

This paper deliberately limits its scope and makes several explicit non-claims:

\begin{itemize}
    \item We do \emph{not} claim that contextual anomaly detection is universally superior to global methods.
    \item We do \emph{not} claim that PNKIF outperforms deep or learned contextual models such as conditional VAEs in all settings.
    \item We do \emph{not} claim to model complex conditional distributions where context alters distributional shape or multimodality.
\end{itemize}

Instead, we focus on the most common and operationally relevant form of contextual dependence, where context primarily induces \emph{location and scale shifts} in behavior (e.g., transaction volume scaling with customer profile). More complex conditional structures may require learned generative models, which introduce additional training complexity and stability concerns beyond the scope of this study.

\section{Related Work}

\subsection{Anomaly Detection in AML}

Machine learning for AML has been extensively surveyed~\cite{chen2018ml}. Common approaches include rule-based systems, supervised classification, and unsupervised anomaly detection. Isolation Forest~\cite{liu2008isolation} is widely used due to its efficiency and effectiveness on high-dimensional data. Recent work by Das et al.~\cite{das2024tree} demonstrates that tree-based ensembles remain state-of-the-art for anomaly discovery in practice, outperforming more complex models while providing interpretable decision boundaries suitable for human review.

\subsection{Contextual Anomaly Detection}

Contextual anomalies are data points that are unusual only within a specific context~\cite{song2007conditional}. Methods include:
\begin{itemize}
    \item \textbf{ROCOD}~\cite{liang2022robust}: K-NN based peer normalization with robust statistics
    \item \textbf{QCAD}~\cite{zhong2023qcad}: Quantile regression for conditional distributions
    \item \textbf{ConQuest}~\cite{calikus2024conquest}: Context discovery for anomaly detection
\end{itemize}

\subsection{Peer Group Analysis}

Bolton and Hand~\cite{bolton2001peer} introduced peer group analysis for fraud detection. The approach groups entities by context features and flags deviations from peer behavior. Our reference implementation formalizes this with kernel-weighted peer normalization.

\section{Methods}

\subsection{Problem Setting}

Given dataset $\{(\mathbf{c}_i, \mathbf{x}_i)\}_{i=1}^{N}$ where $\mathbf{c}_i \in \mathbb{R}^{d_c}$ is the context vector and $\mathbf{x}_i \in \mathbb{R}^{d_x}$ is the behavioral vector, we aim to detect anomalies that are unusual \emph{given their context}.

\subsection{Isolation Forest (IF)}

Isolation Forest~\cite{liu2008isolation} detects anomalies by measuring how easily a point can be isolated via random recursive partitioning. It operates on the concatenated features $[\mathbf{c}; \mathbf{x}]$ or behavior only $\mathbf{x}$, without explicitly modeling context-behavior relationships.

\subsection{Peer-Normalized Kernel Isolation Forest (PNKIF)}

PNKIF is \emph{not} proposed as a novel anomaly detection paradigm. Instead, it serves as a minimal, interpretable reference implementation designed to isolate the effect of peer-based normalization on anomaly scoring. By deliberately avoiding learned representations or deep architectures, observed performance differences can be attributed to \emph{contextual normalization} rather than representational capacity.

The method computes kernel-weighted peer statistics using RBF weights $w_{ij} = \exp(-\|\mathbf{c}_i - \mathbf{c}_j\|^2 / 2\gamma^2)$, then normalizes each point's behavior by its peer mean and standard deviation: $\tilde{\mathbf{x}}_i = (\mathbf{x}_i - \boldsymbol{\mu}_i) / \boldsymbol{\sigma}_i$. Isolation Forest is then applied to the normalized behaviors.

\subsection{On the Role of Random Projections (PNKDIF)}

We evaluated a deep variant (PNKDIF) incorporating frozen random neural projections, inspired by Deep Isolation Forest~\cite{xu2023deep}. PNKDIF projects peer-normalized features through $M$ random MLPs and averages anomaly scores across projections.

Results were mixed: marginal benefit at high contamination ($>$5\%) on geographic swap injection, but inconsistent or degraded performance in other scenarios. This suggests that \emph{peer normalization alone} captures the dominant contextual signal, and additional representational complexity offers limited benefit.

\section{Experimental Setup}

\subsection{Datasets}

We use three public financial datasets:

\begin{itemize}
    \item \textbf{SAML-D}~\cite{oztas2023saml}: Synthetic AML dataset with 30K accounts. Context: geography, payment type, currency (38 features after one-hot encoding). Behavior: transaction statistics (6 features).

    \item \textbf{PaySim}~\cite{lopez2016paysim}: Mobile money simulation with 30K transactions. Context: transaction type (5 features). Behavior: amounts and balances (5 features).

    \item \textbf{Credit Card}~\cite{dal2015calibrating}: Anonymized transactions with 30K samples. Context: time and amount (2 features). Behavior: PCA components V1-V28 (28 features).
\end{itemize}

\subsection{Why Controlled Injection Is Necessary}

Evaluating contextual anomaly detection presents a fundamental challenge: public benchmarks overwhelmingly contain \emph{global} anomalies---samples that are unusual regardless of context.

In such datasets, contextual methods cannot demonstrate their defining capability, because global detectors already succeed. As a result, naive evaluation misleadingly suggests that context provides no benefit.

To isolate the statistical property of interest---conditional deviation given context---we use controlled, domain-grounded injection strategies that satisfy two constraints:

\begin{enumerate}
    \item \textbf{Normal globally:} Injected behaviors are drawn from real samples and lie within the global distribution.
    \item \textbf{Abnormal conditionally:} The same behaviors violate expectations relative to their assigned context.
\end{enumerate}

Importantly, injection does \emph{not} assume fraud semantics, ground-truth labels, or operational realism. It functions as a \textbf{controlled falsification test}, analogous to stress-testing a model under known violations of its assumptions. Without such controlled violations, contextual anomaly detection cannot be meaningfully evaluated.

\subsection{Injection Strategies}

We use domain-grounded strategies motivated by known AML typologies:

\begin{enumerate}
    \item \textbf{Geographic Swap (Contextual):} Simulate geographic arbitrage---a known FATF money laundering typology---by assigning behavior from one geographic region to accounts in another region.

    \item \textbf{Context Mismatch (Contextual):} Simulate account misuse by assigning behavior from a randomly different context group.

    \item \textbf{Velocity Anomaly (Global):} Scale transaction amounts by 2-5x, simulating structuring behavior.

    \item \textbf{Temporal Shift (Global):} Add systematic shifts (2-3 standard deviations) to behavior features.
\end{enumerate}

Injection rates: 1\%, 3\%, 5\%, 10\%.

\subsection{Evaluation Metrics}

We report:
\begin{itemize}
    \item \textbf{AUROC}: Standard ranking metric across 10 random seeds
    \item \textbf{Precision@K}: Precision at top 1\%, 5\%, 10\% of ranked alerts
    \item \textbf{Agreement@K}: Overlap between IF and PNKIF top-K sets
\end{itemize}

Methods compared: IF, IF\_concat, ROCOD~\cite{liang2022robust}, PNKIF, PNKDIF.

\section{Results}

\subsection{Original Labels: Global Anomalies}

On original dataset labels, IF and IF\_concat consistently outperform contextual methods (Table~\ref{tab:original}).

\begin{table}[htbp]
\centering
\caption{AUROC on Original Labels (10 seeds)}
\label{tab:original}
\begin{tabular}{lccccc}
\toprule
Dataset & IF & IF\_concat & ROCOD & PNKIF & PNKDIF \\
\midrule
SAML-D & \textbf{0.937} & 0.896 & 0.419 & 0.869 & 0.842 \\
PaySim & 0.691 & \textbf{0.776} & 0.375 & 0.455 & 0.353 \\
CreditCard & \textbf{0.947} & 0.946 & 0.912 & 0.926 & 0.918 \\
\bottomrule
\end{tabular}
\end{table}

This is expected: original labels correspond to globally unusual behavior that IF detects effectively.

\subsection{Contextual Injection: Peer Methods Win}

On contextual anomalies (context mismatch), peer-normalized methods consistently outperform IF (Table~\ref{tab:contextual}).

\begin{table}[htbp]
\centering
\caption{AUROC on Context Mismatch Injection (PaySim, 10 seeds)}
\label{tab:contextual}
\begin{tabular}{lcccc}
\toprule
Rate & IF & PNKIF & PNKDIF & Winner \\
\midrule
1\% & \textbf{0.650} & 0.536 & 0.469 & IF \\
3\% & 0.615 & \textbf{0.633} & 0.586 & PNKIF \\
5\% & 0.591 & \textbf{0.663} & 0.616 & PNKIF \\
10\% & 0.563 & \textbf{0.690} & 0.677 & PNKIF \\
\bottomrule
\end{tabular}
\end{table}

At low injection rates (1\%), IF still wins because the contextual signal is weak. At higher rates (3-10\%), PNKIF consistently outperforms IF.

\subsection{Extended Precision@K Analysis}

Table~\ref{tab:precisionk} shows precision at multiple K values, directly measuring investigator efficiency.

\begin{table}[htbp]
\centering
\caption{Precision@K by Injection Rate (PaySim, 5 seeds)}
\label{tab:precisionk}
\begin{tabular}{lcccccc}
\toprule
 & \multicolumn{2}{c}{P@1\%} & \multicolumn{2}{c}{P@5\%} & \multicolumn{2}{c}{P@10\%} \\
Rate & IF & PNKIF & IF & PNKIF & IF & PNKIF \\
\midrule
0\% & 13.7\% & 6.8\% & 11.5\% & 4.0\% & 8.7\% & 3.1\% \\
1\% & 13.9\% & 21.1\% & 12.1\% & 11.9\% & 9.5\% & 7.7\% \\
3\% & 15.5\% & 27.7\% & 13.9\% & 21.5\% & 11.7\% & 15.5\% \\
5\% & 17.2\% & 32.3\% & 16.1\% & 30.2\% & 13.6\% & 22.2\% \\
10\% & 22.5\% & \textbf{38.6\%} & 21.1\% & \textbf{38.8\%} & 18.9\% & \textbf{34.0\%} \\
\bottomrule
\end{tabular}
\end{table}

At 10\% contextual contamination:
\begin{itemize}
    \item P@1\%: PNKIF 38.6\% vs IF 22.5\% (\textbf{+72\% improvement})
    \item P@5\%: PNKIF 38.8\% vs IF 21.1\% (\textbf{+84\% improvement})
    \item P@10\%: PNKIF 34.0\% vs IF 18.9\% (\textbf{+80\% improvement})
\end{itemize}

This translates directly to investigator efficiency: reviewing the same number of alerts, PNKIF identifies nearly twice as many true anomalies.

\subsection{Summary Across All Experiments}

\begin{table}[htbp]
\centering
\caption{Win Rate by Injection Type (All Datasets)}
\label{tab:summary}
\begin{tabular}{lccc}
\toprule
Injection Type & IF & PNKIF & PNKDIF \\
\midrule
Context Mismatch & 4/12 & \textbf{8/12} & 0/12 \\
Geographic Swap & 4/12 & 4/12 & \textbf{4/12} \\
Velocity Anomaly & \textbf{12/12} & 0/12 & 0/12 \\
Temporal Shift & \textbf{12/12} & 0/12 & 0/12 \\
\bottomrule
\end{tabular}
\end{table}

\section{A Formalized Diagnostic Test}

\subsection{Statistical Framework}

We formalize the diagnostic interpretation as a hypothesis test:

\begin{itemize}
    \item $H_0$: No contextual structure in the data (IF and PNKIF should agree)
    \item $H_1$: Contextual structure present (IF and PNKIF disagree significantly)
\end{itemize}

\textbf{Test Statistic:} Agreement@5\% = $|S_{IF} \cap S_{PNKIF}| / K$, where $S$ denotes the top-K flagged samples.

\textbf{Decision Rule:} From baseline data (no injection), we compute Agreement@5\% = 29.2\% $\pm$ 3.2\%. Setting threshold at mean $-$ 2$\sigma$ = 22.7\%, we reject $H_0$ if Agreement@5\% $<$ 25\% (rounded for practical use).

\subsection{Diagnostic Metrics}

Table~\ref{tab:diagnostic} shows how agreement and precision evolve with contextual contamination.

\begin{table}[htbp]
\centering
\caption{Diagnostic Metrics: IF vs PNKIF Agreement (PaySim, 5 seeds)}
\label{tab:diagnostic}
\begin{tabular}{lcccc}
\toprule
Injection & Agreement & IF & PNKIF & Test \\
Rate & @5\% & P@5\% & P@5\% & Result \\
\midrule
0\% & 29.2\% & 11.5\% & 4.0\% & Fail to reject $H_0$ \\
1\% & 28.5\% & 12.1\% & 11.9\% & Fail to reject $H_0$ \\
3\% & 26.1\% & 13.9\% & 21.5\% & Fail to reject $H_0$ \\
5\% & 25.0\% & 16.1\% & 30.2\% & Fail to reject $H_0$ \\
10\% & \textbf{24.0\%} & 21.1\% & 38.8\% & \textbf{Reject $H_0$} \\
\bottomrule
\end{tabular}
\end{table}

The test correctly identifies high contextual contamination (10\%) while avoiding false positives at lower rates.

\subsection{Practical Diagnostic Workflow}

\begin{enumerate}
    \item Run IF and PNKIF on your dataset
    \item Compute Agreement@5\% between their top-ranked alerts
    \item If Agreement $<$ 25\%: contextual structure likely present; use PNKIF
    \item If Agreement $\geq$ 25\%: global anomalies dominate; IF is sufficient
    \item For disputed cases: review instances where methods disagree first
\end{enumerate}

This workflow can inform active learning systems~\cite{das2024tree}: instances where IF and PNKIF disagree are natural candidates for human review, as they represent cases where contextual judgment is required.

\section{Regulatory Alignment}

\subsection{FATF Risk-Based Approach}

FATF Recommendation 10 requires financial institutions to apply a \emph{risk-based approach} to customer due diligence, with enhanced measures for higher-risk situations. Peer group analysis directly supports this:

\begin{itemize}
    \item \textbf{Risk segmentation}: Context features (geography, customer type, product) define natural risk segments
    \item \textbf{Proportionate monitoring}: PNKIF flags behavior unusual \emph{for the risk segment}, not globally
    \item \textbf{Documented rationale}: Peer comparison provides clear explanation for why an alert was generated
\end{itemize}

\subsection{SAR Narrative Support}

Suspicious Activity Report (SAR) narratives require explaining \emph{why} activity is suspicious. PNKIF provides natural language justification:

\begin{quote}
``Account exhibited transaction patterns inconsistent with peer accounts in the same geographic segment. While the transaction volume is within normal global ranges, it represents a 3.2 standard deviation departure from accounts with similar profiles.''
\end{quote}

This aligns with BSA/AML narrative requirements and supports examiner review.

\subsection{Model Risk Management (SR 11-7)}

The diagnostic framework supports ongoing model validation:
\begin{itemize}
    \item \textbf{Monitoring}: Track Agreement@5\% over time; sudden drops indicate distributional shift
    \item \textbf{Challenger model}: IF and PNKIF serve as mutual challengers
    \item \textbf{Outcome analysis}: Compare precision of flagged accounts post-investigation
\end{itemize}

\section{Operational Considerations}

\subsection{Computational Performance}

Benchmarked on 30,000 transactions (standard hardware, no GPU):
\begin{itemize}
    \item \textbf{IF}: 0.28 seconds
    \item \textbf{PNKIF}: 3.66 seconds (13x overhead)
    \item \textbf{Throughput}: $\sim$8,200 transactions/second
\end{itemize}

For daily batch processing of 1M transactions, PNKIF requires approximately 2 minutes. The K-NN step dominates; approximate nearest neighbor methods can reduce this further.

\subsection{Implementation Requirements}

\begin{itemize}
    \item \textbf{Dependencies}: scikit-learn, numpy (standard Python stack)
    \item \textbf{Memory}: $O(N \cdot K)$ for peer statistics; scales linearly
    \item \textbf{GPU}: Not required
    \item \textbf{Integration}: Runs as preprocessing layer before existing alerting engine
\end{itemize}

\subsection{Context Feature Selection}

Recommended starting features for AML:
\begin{itemize}
    \item Customer type (retail, corporate, high-net-worth)
    \item Geographic region (domestic, cross-border risk rating)
    \item Account age (tenure bucket)
    \item Product type (deposit, lending, trade finance)
\end{itemize}

Performance degrades when context features are poorly chosen or when peer groups become too small ($n < 10$).

\section{Failure Mode Analysis}

PNKIF fails or underperforms in the following scenarios:

\begin{enumerate}
    \item \textbf{Globally unusual anomalies}: When anomalies stand out globally (e.g., extreme amounts), IF is sufficient and PNKIF adds unnecessary computation.

    \item \textbf{Poor context features}: If context features don't actually determine behavioral norms, peer normalization adds noise rather than signal.

    \item \textbf{Small peer groups}: When $n < 10$ in a peer group, mean/variance estimates become unstable. Minimum peer group size should be enforced.

    \item \textbf{Low contamination}: At $<$1\% anomaly rate, the contextual signal is too weak to detect reliably.

    \item \textbf{Complex conditional distributions}: When context changes distributional \emph{shape} (not just location/scale), PNKIF's z-score normalization is insufficient.

    \item \textbf{Adversarial manipulation}: If adversaries understand peer groups, they may craft behavior that appears normal relative to artificially selected peers.
\end{enumerate}

\section{Discussion}

\subsection{When Does Context Help?}

Our results provide clear guidance:
\begin{itemize}
    \item \textbf{Use IF} when anomalies are globally unusual or contamination is $<$1\%
    \item \textbf{Use PNKIF} when anomalies are contextually unusual and interpretability is needed
    \item \textbf{Use the diagnostic test} when unsure: compute Agreement@5\% to determine if context matters
\end{itemize}

\subsection{Limitations}

\begin{itemize}
    \item \textbf{Injection-based evaluation}: Real contextual labels are rare in public datasets. We frame injection as controlled falsification, not proxy for reality.
    \item \textbf{Location-scale assumption}: Complex conditional distributions require learned models.
    \item \textbf{No real operational data}: Alert reduction and efficiency gains are estimated from precision, not actual investigator outcomes.
\end{itemize}

\section{Conclusion}

We presented an empirical study of contextual vs. global anomaly detection for transaction monitoring. Our key finding is that method effectiveness depends on anomaly type: IF for global anomalies, PNKIF for contextual anomalies. PNKIF achieves up to 84\% higher precision when contextual anomalies are present.

More importantly, we formalized contextual detection as a \emph{diagnostic tool}: the Agreement@5\% test provides a decision rule for when context matters. Our results suggest that \textbf{the first question in anomaly detection should not be ``which model is best?'' but rather ``does context matter at all for this dataset?''}

Open-source implementation is available at [repository URL], requiring no GPU and processing 8,000+ transactions per second.

\section*{Acknowledgment}
Implementation available at: \url{https://github.com/[anonymized]}

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
