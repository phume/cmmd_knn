\section{Conclusion}
\label{sec:conclusion}

We presented Peer-Normalized Kernel Isolation Forest (PNKIF), a diagnostic tool for contextual anomaly detection. Unlike methods that claim universal superiority, PNKIF is designed to \textbf{activate when context matters}:

\begin{itemize}
    \item On contextual anomalies (normal globally, unusual for context): PNKIF achieves $0.95$ AUROC where IF scores $0.50$.
    \item On global anomalies (unusual everywhere): IF matches or exceeds PNKIF---as expected.
    \item \textbf{Diagnostic value}: Divergence between PNKIF and IF signals that contextual structure exists.
\end{itemize}

This framing resolves a tension in CAD evaluation: standard benchmarks are dominated by global anomalies, making CAD methods appear unnecessary. We argue that synthetic/injected data is not a weakness but a \emph{methodological necessity}---without controlled contextual violations, the defining capability of CAD cannot be tested.

On a real anti-money laundering dataset (293K accounts), injecting contextual violations (domestic accounts with cross-border behavior) causes IF to drop from $0.96$ to $0.90$ while PNKIF rises to $0.95$. This demonstrates both the method's effectiveness and the diagnostic framework: the divergence signals that geographic context matters for this detection task.

The method scales as $O(N \log N)$ and requires no training. For practitioners, we recommend running both PNKIF and IF: agreement suggests global anomalies dominate; divergence suggests contextual structure worth investigating.

\subsection{Future Work}

Several directions merit further investigation:

\begin{itemize}
    \item \textbf{Learned context representations}: While our method uses raw context features for K-NN, learning a context embedding (e.g., via contrastive learning) could improve peer selection, especially for high-dimensional or heterogeneous context spaces.

    \item \textbf{Adaptive kernel bandwidth}: The current approach uses a global bandwidth $\gamma$. Local bandwidth adaptation based on neighborhood density could improve performance in contexts with varying scales.

    \item \textbf{Streaming and incremental updates}: Extending PNKDIF to handle streaming data, where new samples arrive and peer statistics must be updated incrementally, would broaden applicability.

    \item \textbf{Theoretical analysis}: Formal analysis of the approximation properties of frozen random projections in the contextual anomaly detection setting would strengthen the theoretical foundation.

    \item \textbf{Multi-modal context}: Extending the framework to handle context features from different modalities (e.g., text, images, graphs) via appropriate embeddings.
\end{itemize}

PNKDIF demonstrates that effective contextual anomaly detection does not require complex training procedures. By leveraging the power of random projections and the efficiency of Isolation Forest, we achieve competitive performance with minimal computational overhead and no risk of overfitting to training data distributions.
