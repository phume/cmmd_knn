\section{Experiments}
\label{sec:experiments}

\subsection{Experimental Setup}

\subsubsection{Datasets}
We evaluate PNKDIF on synthetic and real-world datasets:

\begin{itemize}
    \item \textbf{Synthetic}: Controlled datasets with known ground truth, including linear shift, scale variation, multimodal clusters, and nonlinear manifold anomalies.
    \item \textbf{UCI Adult}: Census income data with demographics as context and work-related features as behavior.
    \item \textbf{UCI Bank}: Marketing campaign data with customer profile as context and campaign statistics as behavior.
    \item \textbf{Cardio (ODDS)}: Cardiology dataset with patient demographics as context and clinical measurements as behavior.
\end{itemize}

\begin{table}[h]
\centering
\caption{Dataset statistics}
\label{tab:datasets}
\begin{tabular}{@{}lrrrr@{}}
\toprule
Dataset & $N$ & $d_c$ & $d_y$ & Anomaly \% \\
\midrule
Syn-Linear & 10,000 & 2 & 5 & 5\% \\
Syn-Scale & 10,000 & 2 & 5 & 5\% \\
Syn-Multimodal & 10,000 & 2 & 5 & 5\% \\
Syn-Nonlinear & 10,000 & 2 & 5 & 5\% \\
Adult (shift) & 30,162 & 5 & 4 & 5\% \\
Bank (shift) & 30,488 & 7 & 9 & 5\% \\
Cardio & 1,831 & 5 & 16 & 9.6\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Baselines}
We compare against the following methods:
\begin{itemize}
    \item \textbf{Isolation Forest (IF)}: Standard IF on behavioral features only.
    \item \textbf{IF-concat}: IF on concatenated context and behavioral features.
    \item \textbf{Deep Isolation Forest (DIF)}: IF with random MLP projections on behavior.
    \item \textbf{DIF-concat}: DIF on concatenated features.
    \item \textbf{QCAD}: Quantile-based conditional anomaly detection~\cite{liang2021conditional}.
    \item \textbf{ROCOD}: Robust conditional outlier detection with peer-based statistics~\cite{liang2023rocod}.
    \item \textbf{LOF}: Local Outlier Factor on concatenated features~\cite{breunig2000lof}.
\end{itemize}

\subsubsection{Evaluation Metrics}
We report:
\begin{itemize}
    \item \textbf{AUROC}: Area under the ROC curve, measuring ranking quality.
    \item \textbf{AUPRC}: Area under the Precision-Recall curve, appropriate for imbalanced data.
    \item \textbf{P@k}: Precision at top-$k$ ranked samples ($k=100$).
\end{itemize}

\subsubsection{Implementation Details}
For PNKDIF, we use $K=100$ neighbors, $M=6$ projections, $d_h=128$ hidden dimensions, $T=100$ trees, and $\psi=256$ subsample size. The kernel bandwidth $\gamma$ is set via the median heuristic. All experiments are run with 5 random seeds and we report mean $\pm$ standard deviation.

\subsection{Results}

\subsubsection{Synthetic Data Performance}

Table~\ref{tab:auroc_synthetic} shows results on synthetic datasets designed to test specific aspects of contextual anomaly detection.

\begin{table}[h]
\centering
\caption{AUROC on synthetic datasets. Best in bold, second-best underlined.}
\label{tab:auroc_synthetic}
\begin{tabular}{@{}lcccc@{}}
\toprule
Method & Linear & Scale & Multimodal & Nonlinear \\
\midrule
IF & 0.660 & 0.967 & 0.501 & 0.820 \\
IF-concat & 0.984 & 0.993 & \underline{0.980} & 0.918 \\
DIF & 0.658 & 0.968 & 0.499 & 0.814 \\
DIF-concat & \underline{0.992} & 0.989 & 0.970 & 0.903 \\
LOF & 0.578 & 0.619 & 0.559 & \underline{0.999} \\
QCAD & 0.990 & 0.990 & 0.528 & 0.962 \\
ROCOD & \textbf{1.000} & \underline{0.999} & 0.676 & \textbf{1.000} \\
\midrule
\textbf{PNKDIF} & \textbf{1.000} & \textbf{0.999} & \textbf{0.867} & \textbf{1.000} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key findings}: (1) On linear shift anomalies, PNKDIF and ROCOD achieve near-perfect detection while standard IF fails (0.66 AUROC). (2) PNKDIF significantly outperforms all methods on multimodal data (+22\% over IF-concat), demonstrating the benefit of peer-aware normalization. (3) On nonlinear manifold anomalies, PNKDIF achieves perfect detection.

Figure~\ref{fig:synthetic} visualizes the comparison.

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/synthetic_comparison.pdf}
\caption{AUROC comparison on synthetic datasets. Red border indicates best method.}
\label{fig:synthetic}
\end{figure}

\subsubsection{Real Data Performance}

Table~\ref{tab:auroc_real} presents results on real-world datasets with synthetic anomaly injection (shift-type).

\begin{table}[h]
\centering
\caption{AUROC on real datasets with shift injection. Best in bold.}
\label{tab:auroc_real}
\begin{tabular}{@{}lccc@{}}
\toprule
Method & Adult & Bank & Cardio \\
\midrule
IF & 0.993 & \textbf{0.999} & \textbf{0.949} \\
DIF & 0.986 & 0.996 & 0.943 \\
LOF & 0.705 & 0.886 & 0.547 \\
QCAD & 0.993 & \textbf{0.999} & 0.709 \\
ROCOD & 0.942 & 0.935 & 0.768 \\
\midrule
PNKDIF & 0.988 & 0.996 & 0.744 \\
PNKDIF-noMLP & \textbf{0.996} & \textbf{0.999} & 0.780 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observations}: (1) On shift-injected anomalies, most methods achieve high AUROC (>0.93), with PNKDIF-noMLP matching or exceeding IF. (2) On Cardio, IF outperforms PNKDIF significantly (0.949 vs 0.780), suggesting the anomalies in this dataset are global outliers rather than contextual. (3) The simpler PNKDIF-noMLP variant often performs best, indicating that random MLP projections may not help when behavioral dimensionality is already low.

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/real_data_comparison.pdf}
\caption{AUROC on real datasets with shift-type anomaly injection.}
\label{fig:real}
\end{figure}

\subsubsection{Ablation Studies}

We evaluate the contribution of each PNKDIF component on the Syn-Nonlinear dataset (Table~\ref{tab:ablation}).

\begin{table}[h]
\centering
\caption{Ablation study on Syn-Nonlinear dataset}
\label{tab:ablation}
\begin{tabular}{@{}lc@{}}
\toprule
Variant & AUROC \\
\midrule
PNKDIF (full) & \textbf{1.0000} \\
w/o kernel weighting (uniform) & 1.0000 \\
w/o MLP projection & 0.9998 \\
w/o peer normalization (DIF) & 0.8145 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Insights}: Peer normalization is the critical component, providing +18.5\% AUROC over DIF. The kernel weighting and MLP projections provide marginal improvements on this dataset. On real data with low-dimensional behavior, the MLP projection may even hurt performance.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\columnwidth]{figures/ablation.pdf}
\caption{Ablation study showing the contribution of each component.}
\label{fig:ablation}
\end{figure}

\subsubsection{Scalability}

Figure~\ref{fig:scalability} shows wall-clock runtime as dataset size increases from $N=1,000$ to $N=50,000$.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\columnwidth]{figures/scalability.pdf}
\caption{Runtime vs. dataset size. PNKDIF scales as $O(N \log N)$.}
\label{fig:scalability}
\end{figure}

PNKDIF maintains competitive runtime, processing 50K samples in ~4 seconds. The overhead versus DIF is ~25\% due to the K-NN step, which is amortized by the efficiency of ball-tree data structures.

\subsubsection{Hyperparameter Sensitivity}

We study sensitivity to the key hyperparameter $K$ (number of neighbors):

\begin{table}[h]
\centering
\caption{Sensitivity to $K$ (AUROC on Syn-Linear)}
\label{tab:k_sensitivity}
\begin{tabular}{@{}lccccc@{}}
\toprule
$K$ & 10 & 25 & 50 & 100 & 200 \\
\midrule
AUROC & 0.985 & 0.996 & 0.999 & \textbf{1.000} & 1.000 \\
\bottomrule
\end{tabular}
\end{table}

PNKDIF is robust across a wide range of $K$ values (25-200). Too small $K$ (<25) leads to noisy peer statistics, while very large $K$ (>500) loses locality. The number of projections $M$ and hidden dimension $d_h$ have minimal impact; even $M=1$ achieves strong performance.

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/hyperparameter_sensitivity.pdf}
\caption{Hyperparameter sensitivity analysis.}
\label{fig:hyperparameter}
\end{figure}
