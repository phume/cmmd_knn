\section{Experiments}
\label{sec:experiments}

\subsection{Experimental Setup}

\subsubsection{Datasets}
We evaluate PNKDIF on several benchmark datasets commonly used in contextual anomaly detection:

\begin{itemize}
    \item \textbf{Synthetic}: Controlled datasets with known ground truth, varying context-behavior relationships and anomaly patterns.
    \item \textbf{Credit Card Fraud}: Financial transaction data with customer demographics as context and transaction features as behavior.
    \item \textbf{Network Intrusion}: Network traffic logs with connection metadata as context and traffic statistics as behavior.
    \item \textbf{Healthcare}: Patient records with demographics as context and clinical measurements as behavior.
\end{itemize}

% TODO: Add specific dataset statistics table
\begin{table}[h]
\centering
\caption{Dataset statistics}
\label{tab:datasets}
\begin{tabular}{@{}lrrrr@{}}
\toprule
Dataset & $N$ & $d_c$ & $d_y$ & Anomaly \% \\
\midrule
Synthetic-Linear & -- & -- & -- & -- \\
Synthetic-Nonlinear & -- & -- & -- & -- \\
Credit Card & -- & -- & -- & -- \\
Network & -- & -- & -- & -- \\
Healthcare & -- & -- & -- & -- \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Baselines}
We compare against the following methods:
\begin{itemize}
    \item \textbf{Isolation Forest (IF)}: Standard IF on concatenated context and behavioral features.
    \item \textbf{Deep Isolation Forest (DIF)}: IF with random MLP projections, without peer normalization.
    \item \textbf{QCAD}: Quantile-based conditional anomaly detection.
    \item \textbf{ROCOD}: Robust conditional outlier detection with peer-based statistics.
    \item \textbf{CVAE}: Conditional VAE with reconstruction-based scoring.
    \item \textbf{LOF}: Local Outlier Factor on concatenated features.
\end{itemize}

\subsubsection{Evaluation Metrics}
We report:
\begin{itemize}
    \item \textbf{AUROC}: Area under the ROC curve, measuring ranking quality.
    \item \textbf{AUPRC}: Area under the Precision-Recall curve, appropriate for imbalanced data.
    \item \textbf{P@k}: Precision at top-$k$ ranked samples.
\end{itemize}

\subsubsection{Implementation Details}
% TODO: Fill in hyperparameters used
For PNKDIF, we use $K=100$ neighbors, $M=6$ projections, $d_h=128$ hidden dimensions, $T=100$ trees, and $\psi=256$ subsample size. The kernel bandwidth $\gamma$ is set via the median heuristic. All experiments are run with 5 random seeds and we report mean $\pm$ standard deviation.

\subsection{Results}

\subsubsection{Overall Performance}

% TODO: Add results table
\begin{table}[h]
\centering
\caption{AUROC comparison across datasets. Best results in bold.}
\label{tab:auroc}
\begin{tabular}{@{}lccccc@{}}
\toprule
Method & Syn-Lin & Syn-NL & Credit & Network & Health \\
\midrule
IF & -- & -- & -- & -- & -- \\
DIF & -- & -- & -- & -- & -- \\
QCAD & -- & -- & -- & -- & -- \\
ROCOD & -- & -- & -- & -- & -- \\
CVAE & -- & -- & -- & -- & -- \\
LOF & -- & -- & -- & -- & -- \\
\textbf{PNKDIF} & -- & -- & -- & -- & -- \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Ablation Studies}

To understand the contribution of each component, we evaluate:
\begin{itemize}
    \item \textbf{PNKDIF w/o kernel}: Uniform peer weighting instead of RBF kernel.
    \item \textbf{PNKDIF w/o MLP}: Direct IF on z-scores without random projection.
    \item \textbf{PNKDIF w/o normalization}: DIF on raw behavioral features.
    \item \textbf{Single projection}: $M=1$ instead of ensemble.
\end{itemize}

% TODO: Add ablation table
\begin{table}[h]
\centering
\caption{Ablation study (AUROC)}
\label{tab:ablation}
\begin{tabular}{@{}lc@{}}
\toprule
Variant & Average AUROC \\
\midrule
PNKDIF (full) & -- \\
w/o kernel weighting & -- \\
w/o MLP projection & -- \\
w/o peer normalization & -- \\
Single projection ($M=1$) & -- \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Scalability}

% TODO: Add runtime analysis
We measure wall-clock time as dataset size increases from $N=1,000$ to $N=1,000,000$. Figure~\ref{fig:scalability} shows that PNKDIF scales near-linearly, consistent with the $O(N \log N)$ complexity analysis.

% TODO: Add figure
% \begin{figure}[h]
% \centering
% \includegraphics[width=0.8\columnwidth]{figures/scalability.pdf}
% \caption{Runtime vs. dataset size}
% \label{fig:scalability}
% \end{figure}

\subsubsection{Hyperparameter Sensitivity}

% TODO: Add sensitivity analysis
We vary each hyperparameter while fixing others to study sensitivity:
\begin{itemize}
    \item $K \in \{25, 50, 100, 200, 400\}$
    \item $M \in \{1, 2, 4, 6, 8, 10\}$
    \item $d_h \in \{32, 64, 128, 256, 512\}$
\end{itemize}

% TODO: Add sensitivity figures
