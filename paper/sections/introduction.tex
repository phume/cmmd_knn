\section{Introduction}

Anomaly detection methods must choose: detect samples that are unusual \emph{globally}, or samples that are unusual \emph{for their context}? Standard methods like Isolation Forest~\cite{liu2008isolation} take the global view, flagging observations that deviate from the overall data distribution. This works well when anomalies are globally distinguishable. But some anomalies are \emph{contextual}: a \$50,000 wire transfer is normal for a corporate account but suspicious for a college student; a heart rate of 180 bpm is expected during exercise but alarming at rest.

This paper addresses a practical question: \textbf{when does context-conditioning help, and how can we detect contextual anomalies when it does?}

We propose Peer-Normalized Kernel Isolation Forest (PNKIF), a training-free method designed as a \emph{diagnostic tool} that activates when context matters. PNKIF identifies contextually similar peers via K-nearest neighbors, normalizes behavioral features against peer statistics, then applies Isolation Forest. The key insight is that this approach:
\begin{itemize}
    \item \textbf{Excels on contextual anomalies}: When behavior is normal globally but unusual for the context, PNKIF achieves $0.95$ AUROC where standard IF scores $0.50$ (random).
    \item \textbf{Matches IF on global anomalies}: When anomalies are globally distinguishable, both methods perform similarly---context-conditioning provides no benefit (as expected).
    \item \textbf{Signals when context matters}: Divergence between PNKIF and IF scores indicates that contextual structure exists in the data.
\end{itemize}

\subsection{Why Synthetic and Injected Anomalies?}

A methodological challenge in evaluating contextual anomaly detection is that \textbf{standard benchmarks are dominated by global anomalies}. Datasets like Cardio, Thyroid, and CreditCard contain anomalies that are unusual everywhere---no context-conditioning is needed to detect them. This makes it impossible to evaluate whether a method can detect truly contextual violations.

We address this through controlled injection: taking real datasets and swapping behavior between context groups (e.g., giving domestic accounts cross-border transaction patterns). This creates anomalies that are:
\begin{itemize}
    \item \textbf{Normal globally}: The injected behavior comes from real samples, so it lies within the global distribution.
    \item \textbf{Unusual for the context}: The behavior is inconsistent with the sample's context group.
\end{itemize}

\textbf{What injection does NOT assume}: We make no assumptions about fraud labels, anomaly semantics, or crime realism. The injection tests a purely \emph{statistical} property: can the method detect conditional deviations? This is the defining capability of contextual anomaly detection.

\subsection{Contributions}

\begin{enumerate}
    \item \textbf{PNKIF}: A training-free contextual anomaly detection method using peer normalization and Isolation Forest. Simple, scalable ($O(N \log N)$), and effective.

    \item \textbf{Diagnostic framework}: We show that comparing PNKIF and IF reveals whether contextual structure exists---a practical tool for practitioners.

    \item \textbf{Methodological clarity}: We argue that synthetic/injected data is not a weakness but a \emph{necessity} for evaluating CAD methods, since global anomalies dominate standard benchmarks.

    \item \textbf{Real-world validation}: On an anti-money laundering dataset (293K accounts), we demonstrate that injecting contextual violations causes IF to degrade while PNKIF improves, confirming real-world applicability.
\end{enumerate}

The remainder of this paper is organized as follows. Section~\ref{sec:related} reviews related work. Section~\ref{sec:method} presents the PNKIF algorithm. Section~\ref{sec:experiments} describes experiments. Section~\ref{sec:discussion} discusses design choices and limitations. Section~\ref{sec:conclusion} concludes.
